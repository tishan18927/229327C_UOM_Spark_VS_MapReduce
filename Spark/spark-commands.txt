#spark-shell
#sc
----
val flights_df = spark.read.option("header", "true").csv("s3://229327c-uom-mapreduce/Data/DelayedFlights-updated.csv")
flights_df.createOrReplaceTempView("delayed_flights")

spark.time(spark.sql("SELECT Year, AVG((CASE WHEN ArrDelay = 0 THEN 0 ELSE CarrierDelay / ArrDelay END) * 100) AS AvgCarrierDelayPercentage FROM delayed_flights WHERE Year >= 2003 AND Year <= 2010 GROUP BY Year").show())

spark.time(spark.sql("SELECT Year, AVG((CASE WHEN ArrDelay = 0 THEN 0 ELSE NASDelay / ArrDelay END) * 100) AS AvgNASDelayPercentage FROM delayed_flights WHERE Year >= 2003 AND Year <= 2010 GROUP BY Year").show())

spark.time(spark.sql("SELECT Year, AVG((CASE WHEN ArrDelay = 0 THEN 0 ELSE WeatherDelay / ArrDelay END) * 100) AS AvgWeatherDelayPercentage FROM delayed_flights WHERE Year >= 2003 AND Year <= 2010 GROUP BY Year").show())

spark.time(spark.sql("SELECT Year, AVG((CASE WHEN ArrDelay = 0 THEN 0 ELSE LateAircraftDelay / ArrDelay END) * 100) AS AvgLateAircraftDelayPercentage FROM delayed_flights WHERE Year >= 2003 AND Year <= 2010 GROUP BY Year").show())

spark.time(spark.sql("SELECT Year, AVG((CASE WHEN ArrDelay = 0 THEN 0 ELSE SecurityDelay / ArrDelay END) * 100) AS AvgSecurityDelayPercentage FROM delayed_flights WHERE Year >= 2003 AND Year <= 2010 GROUP BY Year").show())